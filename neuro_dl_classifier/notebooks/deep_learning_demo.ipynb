{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deep Learning for ECoG/EEG: Interactive Learning Notebook\n",
        "\n",
        "This notebook guides you through:\n",
        "1. Understanding input signal characteristics.\n",
        "2. Building & customizing model architectures.\n",
        "3. Learning model training dynamics.\n",
        "4. Evaluating and debugging model behavior.\n",
        "5. Iterating with realistic testing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ§  1. Understand Input Signal Characteristics\n",
        "\n",
        "We start by generating and inspecting synthetic data to see how signals are structured.\n",
        "\n",
        "**Key concepts:**\n",
        "- Shape: `(batch_size, channels, time)`\n",
        "- Preprocessing: windowing, filtering, segmentation\n",
        "- Why it matters: informs kernel sizes, strides, and pooling operations in your model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from ecog_eeg_dl_classifier.data.simulators.synthetic_signal import generate_synthetic_data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate 1 sample with 4 channels, 256 timesteps\n",
        "X, y = generate_synthetic_data(n_samples=1, n_channels=4, signal_length=256, freq=12)\n",
        "print(f\"X shape: {X.shape}, y: {y}\")\n",
        "\n",
        "# Plot each channel\n",
        "t = range(X.shape[2])\n",
        "plt.figure(figsize=(10, 3))\n",
        "for ch in range(X.shape[1]):\n",
        "    plt.plot(t, X[0, ch], label=f\"Channel {ch}\")\n",
        "plt.title(\"Synthetic EEG/ECoG Sample\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Try it:** Change `freq`, `n_channels`, or introduce more noise in `generate_synthetic_data()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ—ï¸ 2. Build & Customize Model Architectures\n",
        "\n",
        "Explore the baseline CNN and learn layer-by-layer what each does.\n",
        "\n",
        "**Key modules in `models/cnn_baseline.py`:**\n",
        "- `nn.Conv1d(in_channels, out_channels, kernel_size, padding)`\n",
        "- `nn.MaxPool1d(kernel_size, stride)`\n",
        "- `nn.AdaptiveAvgPool1d(1)`\n",
        "- `nn.Flatten()` + `nn.Linear()`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from ecog_eeg_dl_classifier.models.cnn_baseline import EEGCNN\n",
        "import torch\n",
        "\n",
        "# Initialize model for 4-channel input\n",
        "model = EEGCNN(in_channels=4, input_length=256, num_classes=2)\n",
        "print(model)\n",
        "\n",
        "# Forward pass dummy data\n",
        "dummy = torch.randn(2, 4, 256)\n",
        "out = model(dummy)\n",
        "print(f\"Output shape: {out.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Challenge:** Open `cnn_baseline.py` and try:\n",
        "> - Adding a `nn.Dropout(0.5)` after the first pooling layer\n",
        "> - Inserting `nn.BatchNorm1d(num_features)` between `Conv1d` and `ReLU`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŒ€ 3. Learn Model Training Dynamics\n",
        "\n",
        "Inspect the training loop in `training/trainer.py`:\n",
        "- `model.train()`, `loss.backward()`, `optimizer.step()`\n",
        "- Hyperparameters: learning rate, optimizer type, batch size\n",
        "- Enhancements: learning rate scheduler, early stopping, gradient clipping\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from ecog_eeg_dl_classifier.training.trainer import train_model\n",
        "from ecog_eeg_dl_classifier.data.simulators.synthetic_signal import generate_synthetic_data\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch\n",
        "\n",
        "# Prepare data loader\n",
        "data, labels = generate_synthetic_data(n_samples=200, n_channels=4, signal_length=256)\n",
        "loader = DataLoader(TensorDataset(torch.tensor(data), torch.tensor(labels)), batch_size=16)\n",
        "\n",
        "# Train for 3 epochs\n",
        "train_model(model, loader, num_epochs=3, lr=0.005, device=\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Try it:**\n",
        "> - Switch to `torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)`\n",
        "> - Add a scheduler: `torch.optim.lr_scheduler.StepLR`\n",
        "> - Implement early stopping by tracking validation loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“ˆ 4. Evaluate and Debug Model Behavior\n",
        "\n",
        "Use `dashboards/metrics_dashboard.py` to visualize performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from ecog_eeg_dl_classifier.dashboards.metrics_dashboard import plot_metrics\n",
        "from sklearn.metrics import roc_curve, auc, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# Collect predictions\n",
        "y_true, y_pred, y_score = [], [], []\n",
        "model.eval()\n",
        "for xb, yb in loader:\n",
        "    with torch.no_grad():\n",
        "        logits = model(xb)\n",
        "        preds = torch.argmax(logits, dim=1).numpy()\n",
        "        scores = torch.softmax(logits, dim=1)[:,1].numpy()\n",
        "        y_true.extend(yb.numpy())\n",
        "        y_pred.extend(preds)\n",
        "        y_score.extend(scores)\n",
        "\n",
        "# Confusion matrix & accuracy\n",
        "plot_metrics(y_true, y_pred)\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_true, y_score)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(f\"AUC: {roc_auc:.2f}\")\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f\"ROC (area = {roc_auc:.2f})\")\n",
        "plt.plot([0,1],[0,1],\"--\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Extend:** Compute F1-score or per-class precision/recall using `classification_report()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”„ 5. Iterate with Realistic Testing\n",
        "\n",
        "Test real-time inference to see how model handles streaming data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from ecog_eeg_dl_classifier.realtime_integration.data_stream_handler import stream_simulated_signal\n",
        "\n",
        "# Stream and predict every 2 seconds\n",
        "# Uncomment to run:\n",
        "# stream_simulated_signal(model, freq=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Explore:** Change signal `freq` or add Gaussian noise in the stream handler to stress-test the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ§ª Next Steps & Experimentation\n",
        "- Modify data generator: add bandpass filtering or different waveforms\n",
        "- Build deeper or alternative architectures: RNN/LSTM, 1D-Transformer\n",
        "- Integrate preprocessing pipelines: use SciPy for filtering\n",
        "- Deploy to SageMaker endpoint and measure latency\n",
        "\n",
        "Happy learning!"
      ]
    }
  ]
}
